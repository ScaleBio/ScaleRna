/*
* Generate QC reports and metrics on a per sample level
*
*/

// Generate report for each sample from metrics generated in cellMetricsGeneration process
process SampleReportGeneration {
	tag "$id"
	label 'optional'
	label 'report'

	publishDir params.outputDir, mode: 'copy'

	input:
	tuple val(id), val(libName), path("${id}_metrics/allCells.csv"), path("${id}_metrics/allBarcodes.parquet"), val(sampleInfo), val(libCount), path("${id}_metrics/sample_stats.csv"), path("ScalePlex.allBarcodes.parquet"), path("scaleplex_stats.csv"), path("metrics.csv"), val(hashLibName)
	val(libStructName)
	path(libStructDir)
	val(isBarnyard)
	val(outputDirForReport)
	val(mergedSamples)
	
	output:
	path("$outDir/${sampleId}.report.html")
	path("$outDir/csv/${sampleId}.reportStatistics.csv"), emit: stats
	path("$outDir/figures_internal/*"), optional: true
	path("$outDir/csv/${sampleId}_unique_transcript_counts*")
	path("$outDir/csv/${sampleId}_num_cells*")

	script:
	opts = ""
	sampleId = id
	outDir = "reports"
	if (mergedSamples) {
		sampleId = id + ".merged"
		sampleName = id
	} else {
		// This regex splits a string at (.). In this process sampleId == PBMC1.ScaleRNA.
		// The regex splits PBMC1.ScaleRNA into PBMC1 and ScaleRNA
		sampleName = sampleId =~ /(.+)\.(.+)/
		sampleName = sampleName[0][1]
	}
	if (!mergedSamples && libCount > 1) {
		outDir = outDir + "/" + sampleName + "_libraries"
	}
	if (isBarnyard) {
		opts = opts + "--isBarnyard "
    }
	if (params.internalReport) {
		opts = opts + "--internalReport "
	}
	if (params.computeOutDir) {
		opts = opts + "--addOutDir '$outputDirForReport' "
	}
	if (sampleInfo.barcodes) {
		opts = opts + "--barcodes '$sampleInfo.barcodes' "
	}
	if (sampleInfo.libName) {
		opts = opts + "--libName $sampleInfo.libName "
	}
	if (params.scalePlex) {
		if (hashLibName) {
			opts += "--isScalePlex --scalePlexStats scaleplex_stats.csv --scalePlexLibName $hashLibName --scalePlexMetrics metrics.csv --scalePlexAllBarcodes ScalePlex.allBarcodes.parquet "
		} else {
			opts += "--isScalePlex "
		}
	}
	if (params.cellFinder) {
		opts += "--cellFinder "
	}
	libStruct = "${libStructDir}/${libStructName}"
	"""
	export DATAPANE_CDN_BASE="https://d3j2ibc7el7s1k.cloudfront.net/v0.17.0"
	export TMPDIR=\$(mktemp -p `pwd` -d)
	generate_sample_report.py --outDir $outDir --sampleId $sampleId --sampleName $sampleName --libraryStruct $libStruct --sampleMetrics ${id}_metrics \
	--workflowVersion $workflow.manifest.version $opts
	"""
}

// Generate multi sample metric .csv from per-sample csv's
// Called once on all samples in a run (from outside `sampleReport` workflow)
// Takes output from sampleReportGeneration process as input.
process MultiSampleReport {
	label 'optional'

	publishDir file(params.outputDir) / "reports", mode: 'copy'
	
	input:
	path(sampleStats)

	output:
	path(outFn)

	script:
	outFn = "allSamples.reportStatistics.csv"
	"""
	merge_report_stats.py $sampleStats > $outFn
	"""
}

// Run sample metrics generation and per-sample outputs (.mtx, HTML report, ...)
// This is run separately for original samples and merged (grouped) samples when using --merge
workflow SAMPLE_REPORTING {
take:
	samples		// each row from samples.csv parsed into a channel
	libJson  // library structure json file
	isBarnyard // Flag for reporting
	allCells // allCells.csv generated by callCells
	allBarcodes // allBarcodes.parquet generated by callCells
	libCount // value equal to number of sequencing libraries for sample
	sampleStats // sample-level metrics generated by callCells
	scalePlexResults // ScalePlex metrics if --scalePlex
	mergedSamples // If merged run
main:
	// Convert 'expectedCells' column to int
	samples = samples.map{ it.plus(['expectedCells': Utils.toIntOr0(it.expectedCells)]) }

	if (mergedSamples) { 
		// starSoloOuts is already merged by group. We just need to create a combined samples.csv entry per group
		samples
			.map{ [it.group, it] }
			.groupTuple() // All samples grouped for merging, with each column as a list of values
			.map{ // Collapse sample.csv entries for each merged sample (group)
				['id':it[0], 'sample':it[1].sample[1], 'libName':'merged', 
				'expectedCells':it[1].expectedCells.sum(),
				'barcodes': Utils.combineSampleBarcodes(it[1].barcodes)] }
			.dump(tag:'sampleReport/mergedSamples')
			.set{ samples }
	}
	sampleInfo = samples.map{ [it.id, it] } // SampleId -> Dict with all columns from samples.csv
	sampleInfo.dump(tag:'sampleReport/samples')
	
	// sampleMetrics -> [id, libName, allCells.csv, allBarcodes.parquet, sampleInfo, libCount]
	allCells
		.join(allBarcodes.map { it -> [it[0], it[2]] }) // drop libName
		.join(sampleInfo)
		.join(libCount)
		.join(sampleStats)
		.dump(tag:'sampleMetrics')
		.set{ sampleMetrics }
	if (params.scalePlex) {
		sampleMetrics
			.join(scalePlexResults, remainder: true) // [rnaId, cellMetrics, scaleplex_stats.csv, metrics.csv, hashLibName]
			.map{ it ->
				// last element null indicates scalePlexResults is empty
				if (it[-1] == null) {
					// exclude null element and add empty values for scalePlex stats
					it[0..-2] + [[], [], [], '']
				} else {
					it
				}
			}
			.set{ sampleMetrics }
	} else {
		// need to match input cardinality for sampleReportGeneration
		sampleMetrics
			.map{ it + [[], [], [], ''] }
			.set{ sampleMetrics } 
	}
	def outputDirForReport = ""
	if (params.computeOutDir) {
		// only send outputDir to SampleReportGeneration when needed so cache is not invalidated
		outputDirForReport = params.outputDir
	}
	SampleReportGeneration(
		sampleMetrics,
		libJson.getName(),
		libJson.getParent(),
		isBarnyard,
		outputDirForReport,
		mergedSamples
	)

emit:
	sampleStats = SampleReportGeneration.out.stats // metrics csv per sample
}
